{
  "summary": {
    "total_files": 1,
    "files_needing_refactoring": 0,
    "total_large_blocks": 0
  },
  "files": [
    {
      "file": "/Users/q284340/Agentic/nano-degree/docs-content/01_frameworks/Session5_PydanticAI_Type_Safe_Agents.md",
      "total_code_blocks": 43,
      "large_blocks_count": 0,
      "code_blocks": [
        {
          "start_line": 60,
          "end_line": 65,
          "language": "python",
          "content": [
            "from pydantic_ai import Agent, RunContext",
            "from pydantic import BaseModel, Field",
            "from typing import Optional, List",
            "from enum import Enum"
          ],
          "line_count": 4
        },
        {
          "start_line": 81,
          "end_line": 86,
          "language": "python",
          "content": [
            "class DataQuality(str, Enum):",
            "    HIGH = \"high\"",
            "    MEDIUM = \"medium\" ",
            "    LOW = \"low\""
          ],
          "line_count": 4
        },
        {
          "start_line": 90,
          "end_line": 96,
          "language": "python",
          "content": [
            "class FeatureExtractionRequest(BaseModel):",
            "    dataset_id: str = Field(..., min_length=1, max_length=100)",
            "    feature_description: str = Field(..., min_length=5)",
            "    quality_threshold: DataQuality = Field(default=DataQuality.MEDIUM)",
            "    completion_date: Optional[str] = Field(None, regex=r'\\d{4}-\\d{2}-\\d{2}')"
          ],
          "line_count": 5
        },
        {
          "start_line": 100,
          "end_line": 107,
          "language": "python",
          "content": [
            "request = FeatureExtractionRequest(",
            "    dataset_id=\"user_behavior_2024\",",
            "    feature_description=\"Extract features for ML model\",",
            "    quality_threshold=DataQuality.HIGH,",
            "    completion_date=\"2025-01-01\"",
            ")"
          ],
          "line_count": 6
        },
        {
          "start_line": 115,
          "end_line": 120,
          "language": "python",
          "content": [
            "def process_unsafe(data):",
            "    if data.get('quality_threshold') == 'critical':  # Typo!",
            "        apply_validation(data)",
            "    return data"
          ],
          "line_count": 4
        },
        {
          "start_line": 124,
          "end_line": 129,
          "language": "python",
          "content": [
            "def process_safe(request: FeatureExtractionRequest):",
            "    if request.quality_threshold == DataQuality.HIGH:",
            "        apply_validation(request)",
            "    return request"
          ],
          "line_count": 4
        },
        {
          "start_line": 133,
          "end_line": 142,
          "language": "python",
          "content": [
            "try:",
            "    bad_request = FeatureExtractionRequest(",
            "        dataset_id=\"\",  # Too short",
            "        feature_description=\"Short\",  # Too short  ",
            "        quality_threshold=\"invalid\"  # Invalid enum",
            "    )",
            "except ValidationError as e:",
            "    print(f\"Validation failed: {e}\")"
          ],
          "line_count": 8
        },
        {
          "start_line": 152,
          "end_line": 158,
          "language": "python",
          "content": [
            "class FeatureExtractionResponse(BaseModel):",
            "    extraction_id: str",
            "    status: str",
            "    estimated_completion: str",
            "    feature_pipeline_steps: List[str]"
          ],
          "line_count": 5
        },
        {
          "start_line": 162,
          "end_line": 168,
          "language": "python",
          "content": [
            "feature_agent = Agent(",
            "    'openai:gpt-4',",
            "    result_type=FeatureExtractionResponse,",
            "    system_prompt='You are a feature extraction assistant.'",
            ")"
          ],
          "line_count": 5
        },
        {
          "start_line": 172,
          "end_line": 179,
          "language": "python",
          "content": [
            "async def plan_extraction(description: str) -> FeatureExtractionResponse:",
            "    result = await feature_agent.run(",
            "        f\"Plan extraction task: {description}\"",
            "    )",
            "    # Result is guaranteed to be FeatureExtractionResponse",
            "    return result"
          ],
          "line_count": 6
        },
        {
          "start_line": 187,
          "end_line": 195,
          "language": "python",
          "content": [
            "class DataWarehouseDep:",
            "    def __init__(self, warehouse_url: str):",
            "        self.warehouse_url = warehouse_url",
            "    ",
            "    def save_job(self, job_data: dict) -> str:",
            "        # Integration with data warehouses",
            "        return f\"job_{hash(str(job_data)) % 100000}\""
          ],
          "line_count": 7
        },
        {
          "start_line": 199,
          "end_line": 209,
          "language": "python",
          "content": [
            "data_agent = Agent(",
            "    'openai:gpt-4',",
            "    result_type=FeatureExtractionResponse,",
            "    deps_type=DataWarehouseDep",
            ")",
            "",
            "@data_agent.system_prompt  ",
            "def system_prompt(ctx: RunContext[DataWarehouseDep]) -> str:",
            "    return f\"Data assistant. Warehouse: {ctx.deps.warehouse_url}\""
          ],
          "line_count": 9
        },
        {
          "start_line": 213,
          "end_line": 219,
          "language": "python",
          "content": [
            "warehouse = DataWarehouseDep(\"snowflake://company.com\")",
            "result = await data_agent.run(",
            "    \"Create ETL pipeline for customer features\",",
            "    deps=warehouse",
            ")"
          ],
          "line_count": 5
        },
        {
          "start_line": 227,
          "end_line": 235,
          "language": "python",
          "content": [
            "from pydantic import validator, root_validator",
            "",
            "class ValidatedResponse(BaseModel):",
            "    extraction_id: str",
            "    status: str = Field(..., regex=r'^(queued|processing|completed|failed)$')",
            "    estimated_hours: int = Field(..., ge=1, le=168)",
            "    complexity: str = Field(..., regex=r'^(simple|moderate|complex)$')"
          ],
          "line_count": 7
        },
        {
          "start_line": 239,
          "end_line": 245,
          "language": "python",
          "content": [
            "    @validator('extraction_id')",
            "    def validate_id(cls, v):",
            "        if not v.startswith('feat_'):",
            "            raise ValueError('ID must start with \"feat_\"')",
            "        return v"
          ],
          "line_count": 5
        },
        {
          "start_line": 249,
          "end_line": 261,
          "language": "python",
          "content": [
            "    @root_validator",
            "    def validate_complexity_hours(cls, values):",
            "        complexity = values.get('complexity')",
            "        hours = values.get('estimated_hours')",
            "        ",
            "        if complexity == 'simple' and hours > 24:",
            "            raise ValueError('Simple tasks should not exceed 24 hours')",
            "        elif complexity == 'complex' and hours < 48:",
            "            raise ValueError('Complex tasks need at least 48 hours')",
            "        ",
            "        return values"
          ],
          "line_count": 11
        },
        {
          "start_line": 265,
          "end_line": 270,
          "language": "python",
          "content": [
            "validated_agent = Agent(",
            "    'openai:gpt-4',",
            "    result_type=ValidatedResponse",
            ")"
          ],
          "line_count": 4
        },
        {
          "start_line": 278,
          "end_line": 286,
          "language": "python",
          "content": [
            "from pydantic import ValidationError",
            "",
            "async def safe_agent_execution(agent, query: str):",
            "    \"\"\"Execute agent with error handling\"\"\"",
            "    try:",
            "        result = await agent.run(query)",
            "        return {\"success\": True, \"data\": result}"
          ],
          "line_count": 7
        },
        {
          "start_line": 290,
          "end_line": 297,
          "language": "python",
          "content": [
            "    except ValidationError as e:",
            "        return {",
            "            \"success\": False,",
            "            \"error\": \"validation_failed\",",
            "            \"details\": e.errors()",
            "        }"
          ],
          "line_count": 6
        },
        {
          "start_line": 301,
          "end_line": 308,
          "language": "python",
          "content": [
            "    except Exception as e:",
            "        return {",
            "            \"success\": False,",
            "            \"error\": \"execution_failed\", ",
            "            \"details\": str(e)",
            "        }"
          ],
          "line_count": 6
        },
        {
          "start_line": 312,
          "end_line": 323,
          "language": "python",
          "content": [
            "result = await safe_agent_execution(",
            "    validated_agent, ",
            "    \"Plan a complex feature pipeline\"",
            ")",
            "",
            "if result[\"success\"]:",
            "    job_data = result[\"data\"]",
            "    print(f\"Job created: {job_data.extraction_id}\")",
            "else:",
            "    print(f\"Error: {result['error']}\")"
          ],
          "line_count": 10
        },
        {
          "start_line": 333,
          "end_line": 346,
          "language": "python",
          "content": [
            "from pydantic_ai import Tool",
            "",
            "class DataQueryInput(BaseModel):",
            "    sql_query: str = Field(..., min_length=10)",
            "    timeout_seconds: int = Field(default=30, ge=1, le=300)",
            "    format: str = Field(default=\"json\", regex=r'^(json|csv|parquet)$')",
            "",
            "class DataQueryOutput(BaseModel):",
            "    row_count: int",
            "    columns: List[str]",
            "    execution_time: float",
            "    result_preview: str"
          ],
          "line_count": 12
        },
        {
          "start_line": 350,
          "end_line": 359,
          "language": "python",
          "content": [
            "def create_query_tool() -> Tool:",
            "    async def execute_query(input_data: DataQueryInput) -> DataQueryOutput:",
            "        import time",
            "        start_time = time.time()",
            "        ",
            "        # Mock execution - use actual drivers in production",
            "        time.sleep(0.1)  ",
            "        execution_time = time.time() - start_time"
          ],
          "line_count": 8
        },
        {
          "start_line": 363,
          "end_line": 372,
          "language": "python",
          "content": [
            "        return DataQueryOutput(",
            "            row_count=1000000,",
            "            columns=[\"user_id\", \"event_type\", \"timestamp\"],",
            "            execution_time=execution_time,",
            "            result_preview=\"user_id,event_type,timestamp\\n123,click,2024-01-01\"",
            "        )",
            "    ",
            "    return Tool(execute_query, takes=DataQueryInput, returns=DataQueryOutput)"
          ],
          "line_count": 8
        },
        {
          "start_line": 378,
          "end_line": 384,
          "language": "python",
          "content": [
            "query_tool = create_query_tool()",
            "analyst_agent = Agent(",
            "    'openai:gpt-4',",
            "    tools=[query_tool]",
            ")"
          ],
          "line_count": 5
        },
        {
          "start_line": 392,
          "end_line": 406,
          "language": "python",
          "content": [
            "import httpx",
            "from typing import Optional",
            "",
            "class PipelineStatusInput(BaseModel):",
            "    pipeline_id: str = Field(..., min_length=1)",
            "    include_metrics: bool = Field(default=True)",
            "",
            "class PipelineStatusOutput(BaseModel):",
            "    pipeline_id: str",
            "    status: str",
            "    records_processed: int",
            "    throughput_per_second: Optional[float] = None",
            "    error_rate: Optional[float] = None"
          ],
          "line_count": 13
        },
        {
          "start_line": 410,
          "end_line": 423,
          "language": "python",
          "content": [
            "async def create_status_tool() -> Tool:",
            "    async def get_status(input_data: PipelineStatusInput) -> PipelineStatusOutput:",
            "        # Mock API call - use actual API clients in production",
            "        return PipelineStatusOutput(",
            "            pipeline_id=input_data.pipeline_id,",
            "            status=\"running\",",
            "            records_processed=15000000,",
            "            throughput_per_second=2500.5,",
            "            error_rate=0.001",
            "        )",
            "    ",
            "    return Tool(get_status, takes=PipelineStatusInput, returns=PipelineStatusOutput)"
          ],
          "line_count": 12
        },
        {
          "start_line": 427,
          "end_line": 436,
          "language": "python",
          "content": [
            "status_tool = await create_status_tool()",
            "pipeline_agent = Agent(",
            "    'openai:gpt-4', ",
            "    tools=[status_tool],",
            "    result_type=str",
            ")",
            "",
            "result = await pipeline_agent.run(\"Status of pipeline customer-events?\")"
          ],
          "line_count": 8
        },
        {
          "start_line": 444,
          "end_line": 451,
          "language": "python",
          "content": [
            "class AnalysisResponse(BaseModel):",
            "    summary: str",
            "    queries_executed: List[str] = Field(default_factory=list)",
            "    pipeline_status: Optional[PipelineStatusOutput] = None",
            "    confidence_score: float = Field(..., ge=0.0, le=1.0)",
            "    data_quality_score: float = Field(..., ge=0.0, le=1.0)"
          ],
          "line_count": 6
        },
        {
          "start_line": 455,
          "end_line": 465,
          "language": "python",
          "content": [
            "analysis_agent = Agent(",
            "    'openai:gpt-4',",
            "    tools=[query_tool, status_tool],",
            "    result_type=AnalysisResponse,",
            "    system_prompt=\"\"\"",
            "    Data analysis assistant with query and monitoring tools.",
            "    Structure responses with confidence levels.",
            "    \"\"\"",
            ")"
          ],
          "line_count": 9
        },
        {
          "start_line": 469,
          "end_line": 473,
          "language": "python",
          "content": [
            "result = await analysis_agent.run(",
            "    \"Analyze customer trends and check ETL status.\"",
            ")"
          ],
          "line_count": 3
        },
        {
          "start_line": 479,
          "end_line": 500,
          "language": "python",
          "content": [
            "import asyncio",
            "",
            "class RobustTool:",
            "    def __init__(self, tool_func, max_retries=3):",
            "        self.tool_func = tool_func",
            "        self.max_retries = max_retries",
            "    ",
            "    async def execute(self, input_data, retry_count=0):",
            "        try:",
            "            return await self.tool_func(input_data)",
            "        except Exception as e:",
            "            if retry_count < self.max_retries:",
            "                await asyncio.sleep(2 ** retry_count)  # Exponential backoff",
            "                return await self.execute(input_data, retry_count + 1)",
            "            else:",
            "                return {",
            "                    \"error\": True,",
            "                    \"message\": f\"Tool failed after {self.max_retries} retries: {e}\",",
            "                    \"fallback_available\": True",
            "                }"
          ],
          "line_count": 20
        },
        {
          "start_line": 504,
          "end_line": 506,
          "language": "python",
          "content": [
            "robust_tool = RobustTool(query_tool)"
          ],
          "line_count": 1
        },
        {
          "start_line": 516,
          "end_line": 533,
          "language": "python",
          "content": [
            "import pytest",
            "from unittest.mock import AsyncMock",
            "",
            "def test_request_validation():",
            "    valid_request = FeatureExtractionRequest(",
            "        dataset_id=\"user_behavior\",",
            "        feature_description=\"Process user events for ML\",",
            "        quality_threshold=DataQuality.HIGH",
            "    )",
            "    assert valid_request.dataset_id == \"user_behavior\"",
            "",
            "    with pytest.raises(ValidationError):",
            "        FeatureExtractionRequest(",
            "            dataset_id=\"\",  # Too short",
            "            feature_description=\"Short\"  # Too short",
            "        )"
          ],
          "line_count": 16
        },
        {
          "start_line": 537,
          "end_line": 551,
          "language": "python",
          "content": [
            "@pytest.mark.asyncio",
            "async def test_agent_response():",
            "    mock_agent = AsyncMock()",
            "    mock_agent.run.return_value = FeatureExtractionResponse(",
            "        extraction_id=\"feat_123\",",
            "        status=\"queued\", ",
            "        estimated_completion=\"4 hours\",",
            "        feature_pipeline_steps=[\"Ingestion\", \"Transformation\"]",
            "    )",
            "    ",
            "    result = await mock_agent.run(\"Test query\")",
            "    assert result.extraction_id == \"feat_123\"",
            "    assert len(result.feature_pipeline_steps) == 2"
          ],
          "line_count": 13
        },
        {
          "start_line": 557,
          "end_line": 578,
          "language": "python",
          "content": [
            "from pydantic import BaseSettings",
            "",
            "class AgentConfig(BaseSettings):",
            "    model_name: str = \"openai:gpt-4\"",
            "    max_tokens: int = 2000",
            "    temperature: float = 0.3",
            "    api_key: Optional[str] = None",
            "    warehouse_url: str = \"snowflake://localhost\"",
            "    ",
            "    class Config:",
            "        env_prefix = \"AGENT_\"",
            "        env_file = \".env\"",
            "",
            "config = AgentConfig()",
            "",
            "production_agent = Agent(",
            "    config.model_name,",
            "    result_type=FeatureExtractionResponse,",
            "    system_prompt=\"Production assistant\"",
            ")"
          ],
          "line_count": 20
        },
        {
          "start_line": 586,
          "end_line": 591,
          "language": "python",
          "content": [
            "from fastapi import FastAPI, HTTPException",
            "from pydantic import ValidationError",
            "",
            "app = FastAPI()"
          ],
          "line_count": 4
        },
        {
          "start_line": 595,
          "end_line": 603,
          "language": "python",
          "content": [
            "@app.post(\"/extract-features\", response_model=FeatureExtractionResponse)",
            "async def extract_features(request: FeatureExtractionRequest):",
            "    try:",
            "        result = await feature_agent.run(",
            "            f\"Extract from: {request.dataset_id} - {request.feature_description}\"",
            "        )",
            "        return result"
          ],
          "line_count": 7
        },
        {
          "start_line": 607,
          "end_line": 612,
          "language": "python",
          "content": [
            "    except ValidationError as e:",
            "        raise HTTPException(status_code=422, detail=e.errors())",
            "    except Exception as e:",
            "        raise HTTPException(status_code=500, detail=str(e))"
          ],
          "line_count": 4
        },
        {
          "start_line": 616,
          "end_line": 620,
          "language": "python",
          "content": [
            "@app.get(\"/health\")",
            "async def health():",
            "    return {\"status\": \"healthy\", \"version\": \"1.0.0\"}"
          ],
          "line_count": 3
        },
        {
          "start_line": 630,
          "end_line": 642,
          "language": "python",
          "content": [
            "class DataQualityRequest(BaseModel):",
            "    dataset_name: str",
            "    max_rows: int = Field(..., ge=1000, le=10000000)",
            "    ",
            "class DataQualityReport(BaseModel):",
            "    dataset_name: str",
            "    total_rows: int",
            "    missing_values_pct: float",
            "    duplicate_rows_pct: float",
            "    quality_score: float",
            "    recommendations: List[str]"
          ],
          "line_count": 11
        },
        {
          "start_line": 646,
          "end_line": 653,
          "language": "python",
          "content": [
            "def create_quality_agent():",
            "    return Agent(",
            "        'openai:gpt-4',",
            "        result_type=DataQualityReport,",
            "        system_prompt=\"You are a data quality assistant.\"",
            "    )"
          ],
          "line_count": 6
        },
        {
          "start_line": 657,
          "end_line": 660,
          "language": "python",
          "content": [
            "agent = create_quality_agent()",
            "result = await agent.run(\"Assess customer_events dataset with 5M rows\")"
          ],
          "line_count": 2
        }
      ],
      "large_blocks": [],
      "needs_refactoring": false
    }
  ]
}